{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f5754a",
   "metadata": {
    "papermill": {
     "duration": 0.006327,
     "end_time": "2025-08-27T11:10:19.608023",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.601696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec2d10e",
   "metadata": {
    "papermill": {
     "duration": 0.004302,
     "end_time": "2025-08-27T11:10:19.616950",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.612648",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>★ Implementation - Xception ★"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9595d2e",
   "metadata": {
    "papermill": {
     "duration": 0.004137,
     "end_time": "2025-08-27T11:10:19.625531",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.621394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/Masterx-AI/Xception_Implementation/main/xception.jpg\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd1e2ba",
   "metadata": {
    "papermill": {
     "duration": 0.004108,
     "end_time": "2025-08-27T11:10:19.633796",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.629688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2c196c",
   "metadata": {
    "papermill": {
     "duration": 0.003993,
     "end_time": "2025-08-27T11:10:19.641988",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.637995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Objective:\n",
    "- Understand the Model Architecture\n",
    "- Reconstruct the Model Architecture from scratch\n",
    "- Perform a dry run test to assess it's implemenation on real-time data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0786b0",
   "metadata": {
    "papermill": {
     "duration": 0.004058,
     "end_time": "2025-08-27T11:10:19.650313",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.646255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0089e1",
   "metadata": {
    "papermill": {
     "duration": 0.004019,
     "end_time": "2025-08-27T11:10:19.658541",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.654522",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Xception Model Description:\n",
    "\n",
    "onvolutional Neural Networks (CNN) have come a long way, from the LeNet-style, AlexNet, VGG models, which used simple stacks of convolutional layers for feature extraction and max-pooling layers for spatial sub-sampling, stacked one after the other, to Inception and ResNet networks which use skip connections and multiple convolutional and max-pooling blocks in each layer. Since its introduction, one of the best networks in computer vision has been the Inception network. The Inception model uses a stack of modules, each module containing a bunch of feature extractors, which allow them to learn richer representations with fewer parameters.\n",
    "\n",
    "Xception paper — https://arxiv.org/abs/1610.02357\n",
    "\n",
    "The Xception module has 3 main parts. The Entry flow, the Middle flow (which is repeated 8 times), and the Exit flow.\n",
    "\n",
    "\n",
    "Entry flow of the Xception architecture (Source: Image from the original paper)\n",
    "The entry flow has two blocks of convolutional layer followed by a ReLU activation. The diagram also mentions in detail the number of filters, the filter size (kernel size), and the strides.\n",
    "\n",
    "There are also various Separable convolutional layers. There are also Max Pooling layers. When the strides are different than one, the strides are also mentioned. There are also Skip connections, where we use ‘ADD’ to merge the two tensors. It also shows the shape of the input tensor in each flow. For example, we begin with an image size of 299x299x3, and after the entry flow, we get an image size of 19x19x728.\n",
    "\n",
    "\n",
    "Middle and Exit flow of Xception architecture (Source: Image from the original paper)\n",
    "Similarly, for the Middle flow and the Exit flow, this diagram clearly explains the image size, the various layers, the number of filters, the shape of filters, the type of pooling, the number of repetitions, and the option of adding a fully connected layer in the end.\n",
    "\n",
    "Also, all Convolutional and Separable Convolutional layers are followed by batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31eb4204",
   "metadata": {
    "papermill": {
     "duration": 0.004009,
     "end_time": "2025-08-27T11:10:19.666606",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.662597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76ea54c",
   "metadata": {
    "papermill": {
     "duration": 0.004026,
     "end_time": "2025-08-27T11:10:19.674730",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.670704",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <center> Stractegic Plan of Action:\n",
    "    \n",
    "**We aim to solve the problem statement by creating a plan of action, Here are some of the necessary steps:**\n",
    "1. Dataset Prepration\n",
    "2. Model Development\n",
    "3. Model Testing\n",
    "4. Project Outcomes & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874cb35",
   "metadata": {
    "papermill": {
     "duration": 0.003946,
     "end_time": "2025-08-27T11:10:19.683025",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.679079",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8922f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:10:19.693015Z",
     "iopub.status.busy": "2025-08-27T11:10:19.692582Z",
     "iopub.status.idle": "2025-08-27T11:10:30.222314Z",
     "shell.execute_reply": "2025-08-27T11:10:30.221076Z"
    },
    "papermill": {
     "duration": 10.53781,
     "end_time": "2025-08-27T11:10:30.225015",
     "exception": false,
     "start_time": "2025-08-27T11:10:19.687205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.8.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1797c8c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:10:30.237056Z",
     "iopub.status.busy": "2025-08-27T11:10:30.236214Z",
     "iopub.status.idle": "2025-08-27T11:10:33.603681Z",
     "shell.execute_reply": "2025-08-27T11:10:33.602706Z"
    },
    "papermill": {
     "duration": 3.375359,
     "end_time": "2025-08-27T11:10:33.605512",
     "exception": false,
     "start_time": "2025-08-27T11:10:30.230153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(f'Number of GPUs available: {num_gpus}')\n",
    "\n",
    "# Optionally, print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(f'GPU {i}: {torch.cuda.get_device_name(i)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc4fe87",
   "metadata": {
    "papermill": {
     "duration": 0.004227,
     "end_time": "2025-08-27T11:10:33.614249",
     "exception": false,
     "start_time": "2025-08-27T11:10:33.610022",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <center> 1. Dataset Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66e19f62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:10:33.624485Z",
     "iopub.status.busy": "2025-08-27T11:10:33.623691Z",
     "iopub.status.idle": "2025-08-27T11:10:43.096357Z",
     "shell.execute_reply": "2025-08-27T11:10:43.095089Z"
    },
    "papermill": {
     "duration": 9.480149,
     "end_time": "2025-08-27T11:10:43.098809",
     "exception": false,
     "start_time": "2025-08-27T11:10:33.618660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Importing the basic librarires\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Preparing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b95760a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:10:43.109895Z",
     "iopub.status.busy": "2025-08-27T11:10:43.109579Z",
     "iopub.status.idle": "2025-08-27T11:10:49.202968Z",
     "shell.execute_reply": "2025-08-27T11:10:49.202178Z"
    },
    "papermill": {
     "duration": 6.101349,
     "end_time": "2025-08-27T11:10:49.205129",
     "exception": false,
     "start_time": "2025-08-27T11:10:43.103780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:13<00:00, 12.5MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Preparing the dataset\n",
    "# Define preprocessing for training and validation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((320, 320)),  # Resize to allow random cropping\n",
    "    transforms.RandomResizedCrop(299),  # Random crop to 299x299\n",
    "    transforms.RandomHorizontalFlip(),  # Augmentation for training\n",
    "    transforms.ToTensor(),  # Convert to tensor (scales to [0, 1])\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet normalization\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),  # Resize directly to 299x299\n",
    "    transforms.CenterCrop(299),  # Center crop for consistency\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Download and load CIFAR10 training data\n",
    "full_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Split train set into training and validation (e.g., 45k train, 5k val)\n",
    "train_size = int(0.9 * len(full_trainset))\n",
    "val_size = len(full_trainset) - train_size\n",
    "train_set, val_set = random_split(full_trainset, [train_size, val_size])\n",
    "\n",
    "# For validation, use test transform (no augmentation)\n",
    "val_set.dataset.transform = transform_test\n",
    "\n",
    "# Load CIFAR10 test dataset\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aa5c40",
   "metadata": {
    "papermill": {
     "duration": 0.004599,
     "end_time": "2025-08-27T11:10:49.215789",
     "exception": false,
     "start_time": "2025-08-27T11:10:49.211190",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acef1d6",
   "metadata": {
    "papermill": {
     "duration": 0.004598,
     "end_time": "2025-08-27T11:10:49.225359",
     "exception": false,
     "start_time": "2025-08-27T11:10:49.220761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <center>2. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54756fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:10:49.236883Z",
     "iopub.status.busy": "2025-08-27T11:10:49.236538Z",
     "iopub.status.idle": "2025-08-27T11:11:08.115162Z",
     "shell.execute_reply": "2025-08-27T11:11:08.114256Z"
    },
    "papermill": {
     "duration": 18.886866,
     "end_time": "2025-08-27T11:11:08.117110",
     "exception": false,
     "start_time": "2025-08-27T11:10:49.230244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "Xception                                      [1, 10]                   --\n",
       "├─EntryFlow: 1-1                              [1, 728, 19, 19]          --\n",
       "│    └─Conv2d: 2-1                            [1, 32, 150, 150]         896\n",
       "│    └─BatchNorm2d: 2-2                       [1, 32, 150, 150]         64\n",
       "│    └─Conv2d: 2-3                            [1, 64, 150, 150]         18,496\n",
       "│    └─BatchNorm2d: 2-4                       [1, 64, 150, 150]         128\n",
       "│    └─ModuleList: 2-9                        --                        (recursive)\n",
       "│    │    └─Sequential: 3-1                   [1, 128, 75, 75]          26,816\n",
       "│    └─ModuleList: 2-10                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-2                       [1, 128, 75, 75]          8,320\n",
       "│    └─ModuleList: 2-9                        --                        (recursive)\n",
       "│    │    └─Sequential: 3-3                   [1, 256, 38, 38]          102,784\n",
       "│    └─ModuleList: 2-10                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-4                       [1, 256, 38, 38]          33,024\n",
       "│    └─ModuleList: 2-9                        --                        (recursive)\n",
       "│    │    └─Sequential: 3-5                   [1, 728, 19, 19]          728,120\n",
       "│    └─ModuleList: 2-10                       --                        (recursive)\n",
       "│    │    └─Conv2d: 3-6                       [1, 728, 19, 19]          187,096\n",
       "├─MiddleFlow: 1-2                             [1, 728, 19, 19]          --\n",
       "│    └─ModuleList: 2-11                       --                        --\n",
       "│    │    └─Sequential: 3-7                   [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-8                   [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-9                   [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-10                  [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-11                  [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-12                  [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-13                  [1, 728, 19, 19]          1,613,976\n",
       "│    │    └─Sequential: 3-14                  [1, 728, 19, 19]          1,613,976\n",
       "├─ExitFlow: 1-3                               [1, 10]                   --\n",
       "│    └─ReLU: 2-12                             [1, 728, 19, 19]          --\n",
       "│    └─SeparableConv2D: 2-13                  [1, 728, 19, 19]          --\n",
       "│    │    └─Conv2d: 3-15                      [1, 728, 19, 19]          6,552\n",
       "│    │    └─Conv2d: 3-16                      [1, 728, 19, 19]          529,984\n",
       "│    └─BatchNorm2d: 2-14                      [1, 728, 19, 19]          1,456\n",
       "│    └─ReLU: 2-15                             [1, 728, 19, 19]          --\n",
       "│    └─SeparableConv2D: 2-16                  [1, 1024, 19, 19]         --\n",
       "│    │    └─Conv2d: 3-17                      [1, 728, 19, 19]          6,552\n",
       "│    │    └─Conv2d: 3-18                      [1, 1024, 19, 19]         745,472\n",
       "│    └─BatchNorm2d: 2-17                      [1, 1024, 19, 19]         2,048\n",
       "│    └─MaxPool2d: 2-18                        [1, 1024, 10, 10]         --\n",
       "│    └─Conv2d: 2-19                           [1, 1024, 10, 10]         746,496\n",
       "│    └─SeparableConv2D: 2-20                  [1, 1536, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-19                      [1, 1024, 10, 10]         9,216\n",
       "│    │    └─Conv2d: 3-20                      [1, 1536, 10, 10]         1,572,864\n",
       "│    └─BatchNorm2d: 2-21                      [1, 1536, 10, 10]         3,072\n",
       "│    └─ReLU: 2-22                             [1, 1536, 10, 10]         --\n",
       "│    └─SeparableConv2D: 2-23                  [1, 2048, 10, 10]         --\n",
       "│    │    └─Conv2d: 3-21                      [1, 1536, 10, 10]         13,824\n",
       "│    │    └─Conv2d: 3-22                      [1, 2048, 10, 10]         3,145,728\n",
       "│    └─BatchNorm2d: 2-24                      [1, 2048, 10, 10]         4,096\n",
       "│    └─ReLU: 2-25                             [1, 2048, 10, 10]         --\n",
       "│    └─AdaptiveAvgPool2d: 2-26                [1, 2048, 1, 1]           --\n",
       "│    └─Linear: 2-27                           [1, 10]                   20,490\n",
       "===============================================================================================\n",
       "Total params: 20,825,402\n",
       "Trainable params: 20,825,402\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 8.47\n",
       "===============================================================================================\n",
       "Input size (MB): 1.07\n",
       "Forward/backward pass size (MB): 454.77\n",
       "Params size (MB): 83.30\n",
       "Estimated Total Size (MB): 539.14\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the Xception Model Architecture\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SeparableConv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1):\n",
    "        super(SeparableConv2D, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class EntryFlow(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EntryFlow, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block_sizes = [128, 256, 728]\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for i, size in enumerate(self.block_sizes):\n",
    "            in_channels = 64 if i == 0 else self.block_sizes[i-1]\n",
    "            block = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                SeparableConv2D(in_channels, size, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(size),\n",
    "                nn.ReLU(),\n",
    "                SeparableConv2D(size, size, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(size),\n",
    "                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            )\n",
    "            self.blocks.append(block)\n",
    "        self.residual_convs = nn.ModuleList([\n",
    "            nn.Conv2d(64, 128, kernel_size=1, stride=2, padding=0),\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=2, padding=0),\n",
    "            nn.Conv2d(256, 728, kernel_size=1, stride=2, padding=0),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        previous_block_activation = x\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x1 = block(previous_block_activation)\n",
    "            residual = self.residual_convs[i](previous_block_activation)\n",
    "            x = x1 + residual\n",
    "            previous_block_activation = x\n",
    "        return x\n",
    "\n",
    "class MiddleFlow(nn.Module):\n",
    "    def __init__(self, num_blocks=8):\n",
    "        super(MiddleFlow, self).__init__()\n",
    "        self.num_blocks = num_blocks\n",
    "        self.blocks = nn.ModuleList([])\n",
    "        for _ in range(num_blocks):\n",
    "            self.blocks.append(nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                SeparableConv2D(728, 728, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(728),\n",
    "                nn.ReLU(),\n",
    "                SeparableConv2D(728, 728, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(728),\n",
    "                nn.ReLU(),\n",
    "                SeparableConv2D(728, 728, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(728),\n",
    "            ))\n",
    "\n",
    "    def forward(self, x):\n",
    "        previous_block_activation = x\n",
    "        for block in self.blocks:\n",
    "            x1 = block(x)\n",
    "            x = x1 + previous_block_activation\n",
    "            previous_block_activation = x\n",
    "        return x\n",
    "\n",
    "class ExitFlow(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ExitFlow, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sepconv1 = SeparableConv2D(728, 728, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(728)\n",
    "        self.sepconv2 = SeparableConv2D(728, 1024, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(1024)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.residual_conv = nn.Conv2d(728, 1024, kernel_size=1, stride=2)\n",
    "\n",
    "        self.sepconv3 = SeparableConv2D(1024, 1536, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "        self.sepconv4 = SeparableConv2D(1536, 2048, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        previous_block_activation = x\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(self.sepconv1(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(self.sepconv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        residual = self.residual_conv(previous_block_activation)\n",
    "        x = x + residual\n",
    "\n",
    "        x = self.bn3(self.sepconv3(x))\n",
    "        x = self.relu(x)\n",
    "        x = self.bn4(self.sepconv4(x))\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Xception, self).__init__()\n",
    "        self.entry_flow = EntryFlow()\n",
    "        self.middle_flow = MiddleFlow()\n",
    "        self.exit_flow = ExitFlow(num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.entry_flow(x)\n",
    "        x = self.middle_flow(x)\n",
    "        x = self.exit_flow(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = Xception(num_classes=10)\n",
    "\n",
    "\n",
    "# Checking Model Summary\n",
    "from torchinfo import summary\n",
    "summary(model, input_size=(1, 3, 299, 299))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0fb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:11:08.128683Z",
     "iopub.status.busy": "2025-08-27T11:11:08.128422Z",
     "iopub.status.idle": "2025-08-27T11:12:00.235554Z",
     "shell.execute_reply": "2025-08-27T11:12:00.234330Z"
    },
    "papermill": {
     "duration": 52.119532,
     "end_time": "2025-08-27T11:12:00.241793",
     "exception": false,
     "start_time": "2025-08-27T11:11:08.122261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tf/6xh9btr16qd9jsvlhmr3vc780000gn/T/ipykernel_18474/423322318.py:18: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # For dynamic gradient scaling\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 127\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m epoch_loss, accuracy\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# Final evaluation on test set\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[10], line 114\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, loader, criterion, device)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[1;32m    113\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 114\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m    117\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:173\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataParallel.forward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids:\n\u001b[0;32m--> 173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mbuffers()):\n\u001b[1;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msrc_device_obj:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 130\u001b[0m, in \u001b[0;36mXception.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 130\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mentry_flow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmiddle_flow(x)\n\u001b[1;32m    132\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexit_flow(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 51\u001b[0m, in \u001b[0;36mEntryFlow.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m previous_block_activation \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[0;32m---> 51\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_block_activation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_convs[i](previous_block_activation)\n\u001b[1;32m     53\u001b[0m     x \u001b[38;5;241m=\u001b[39m x1 \u001b[38;5;241m+\u001b[39m residual\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[9], line 14\u001b[0m, in \u001b[0;36mSeparableConv2D.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepthwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpointwise(x)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Assume model, train_loader, val_loader defined and moved to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Xception(num_classes=10)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define learning rate scheduler (decay lr by 0.94 every 2 epochs)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.94)\n",
    "scaler = GradScaler()  # For dynamic gradient scaling\n",
    "\n",
    "\n",
    "def train_and_validate(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=5):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'time_per_epochs': []\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            # Step the scheduler to update learning rate\n",
    "            #scheduler.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_loss = running_loss / total\n",
    "        train_acc = correct / total\n",
    "        step_time = time.time() - start\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_loss = running_loss / total\n",
    "        val_acc = correct / total\n",
    "        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Save metrics for each epoch\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['time_per_epochs'].append(step_time)\n",
    "        \n",
    "    # Convert dictionary to JSON string\n",
    "    history =  json.dumps(history) \n",
    "    \n",
    "    # Option 2: Write the JSON string  to a file\n",
    "    with open('../histories/history_xception.json', 'w') as f:\n",
    "        f.write(history)\n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "# model, history = train_and_validate(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=5)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    accuracy = correct / total\n",
    "    return epoch_loss, accuracy\n",
    "\n",
    "# Final evaluation on test set\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc234d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T11:12:00.253318Z",
     "iopub.status.busy": "2025-08-27T11:12:00.252941Z",
     "iopub.status.idle": "2025-08-27T12:14:37.811337Z",
     "shell.execute_reply": "2025-08-27T12:14:37.810204Z"
    },
    "papermill": {
     "duration": 3757.572313,
     "end_time": "2025-08-27T12:14:37.819238",
     "exception": false,
     "start_time": "2025-08-27T11:12:00.246925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "model, history = train_and_validate(model, train_loader, val_loader, optimizer, criterion, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57c09a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T12:14:37.831231Z",
     "iopub.status.busy": "2025-08-27T12:14:37.830906Z",
     "iopub.status.idle": "2025-08-27T12:14:38.251820Z",
     "shell.execute_reply": "2025-08-27T12:14:38.251090Z"
    },
    "papermill": {
     "duration": 0.429452,
     "end_time": "2025-08-27T12:14:38.253929",
     "exception": false,
     "start_time": "2025-08-27T12:14:37.824477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, '../models/xception_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f9ea8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T12:14:38.266379Z",
     "iopub.status.busy": "2025-08-27T12:14:38.266091Z",
     "iopub.status.idle": "2025-08-27T12:14:38.273228Z",
     "shell.execute_reply": "2025-08-27T12:14:38.272326Z"
    },
    "papermill": {
     "duration": 0.015437,
     "end_time": "2025-08-27T12:14:38.275081",
     "exception": false,
     "start_time": "2025-08-27T12:14:38.259644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n",
    "    plt.title('Loss vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n",
    "    plt.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n",
    "    plt.title('Accuracy vs Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d6a732",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T12:14:38.287474Z",
     "iopub.status.busy": "2025-08-27T12:14:38.286561Z",
     "iopub.status.idle": "2025-08-27T12:15:42.560837Z",
     "shell.execute_reply": "2025-08-27T12:15:42.559812Z"
    },
    "papermill": {
     "duration": 64.282218,
     "end_time": "2025-08-27T12:15:42.562722",
     "exception": false,
     "start_time": "2025-08-27T12:14:38.280504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n",
    "history = json.loads(history)\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee24a141",
   "metadata": {
    "papermill": {
     "duration": 0.005913,
     "end_time": "2025-08-27T12:15:42.574916",
     "exception": false,
     "start_time": "2025-08-27T12:15:42.569003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a1abde",
   "metadata": {
    "papermill": {
     "duration": 0.005851,
     "end_time": "2025-08-27T12:15:42.586521",
     "exception": false,
     "start_time": "2025-08-27T12:15:42.580670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center>4. Project Outcomes & Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc85430",
   "metadata": {
    "papermill": {
     "duration": 0.006301,
     "end_time": "2025-08-27T12:15:42.598838",
     "exception": false,
     "start_time": "2025-08-27T12:15:42.592537",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Here are some of the key outcomes of the project:\n",
    "\n",
    "- The Model Architecture was reconstructed from scratch with no errors.\n",
    "- We were able to plot the model graph & observe input & output shapes of all the layers. \n",
    "- Also we could identify that the total trainable paramters for the Xception model were 20.8M.\n",
    "- To demonstrate it's functionality, we have tested the model for just 10 epochs (due to hardware limitations). \n",
    "- Despite this, the model has performed surpisingly well achieving high accuracy within few iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a395a17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-27T12:15:42.612303Z",
     "iopub.status.busy": "2025-08-27T12:15:42.611961Z",
     "iopub.status.idle": "2025-08-27T12:15:42.616077Z",
     "shell.execute_reply": "2025-08-27T12:15:42.615207Z"
    },
    "papermill": {
     "duration": 0.013034,
     "end_time": "2025-08-27T12:15:42.617787",
     "exception": false,
     "start_time": "2025-08-27T12:15:42.604753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#<<<--------------------------------------THE END---------------------------------------->>>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30204,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3936.804452,
   "end_time": "2025-08-27T12:15:46.600616",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-27T11:10:09.796164",
   "version": "2.3.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "14b81f02ad9345108f9affc258d518d4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2f9e7d98281049ef87cb66fa23bf521a",
       "placeholder": "​",
       "style": "IPY_MODEL_a1692a81fa2847578c5964144f97acb9",
       "value": " 170499072/? [00:02&lt;00:00, 78290186.56it/s]"
      }
     },
     "1bef3b94ff524a1aa8d015f38b06000f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9382654c26b44e8a82141cc6346bd4e5",
        "IPY_MODEL_c91f091438fd45a4a633317e851d3136",
        "IPY_MODEL_14b81f02ad9345108f9affc258d518d4"
       ],
       "layout": "IPY_MODEL_ff49e2932f0e45b78936462f55d01a9c"
      }
     },
     "24d16271863c49db8d86793f45dcabb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f9e7d98281049ef87cb66fa23bf521a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "677f96d8540b452c897f9f2d38621082": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7762f7527331492a883a7455a8b94633": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9382654c26b44e8a82141cc6346bd4e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_24d16271863c49db8d86793f45dcabb2",
       "placeholder": "​",
       "style": "IPY_MODEL_f84061401f154ff280bbbc6a81f41c9a",
       "value": ""
      }
     },
     "a1692a81fa2847578c5964144f97acb9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c91f091438fd45a4a633317e851d3136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_677f96d8540b452c897f9f2d38621082",
       "max": 170498071,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7762f7527331492a883a7455a8b94633",
       "value": 170498071
      }
     },
     "f84061401f154ff280bbbc6a81f41c9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ff49e2932f0e45b78936462f55d01a9c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
